{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2994\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import tweepy\n",
    "import json\n",
    "import re\n",
    "import operator \n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "\n",
    "def get_tokens():\n",
    "   with open('FirstContactWithTensorFlow.txt', 'r') as tf:\n",
    "    text = tf.read()\n",
    "    lowers = text.lower()\n",
    "    #tokens = nltk.word_tokenize(text)\n",
    "    puntuaci√≥ntext_no_punctuation = lowers.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "    #lowers = text.lower()\n",
    "    #no_punctuation = lowers.translate(None, string.punctuation)\n",
    "    tokens = nltk.word_tokenize(puntuaci√≥ntext_no_punctuation)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "##### Task 2.6 ######\n",
    "\n",
    "tokens = get_tokens()\n",
    "#count = Counter(tokens)\n",
    "#print(count)\n",
    "filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "count = Counter(filtered)\n",
    "print(len(count))\n",
    "\n",
    "\n",
    "###### Task 2.7 #######\n",
    "\n",
    "# Nos conectamos con la API de tweepy\n",
    "consumer_key = 'X5EqKwcj2QSpcSlsqoBi29eCb'\n",
    "consumer_secret = '6i9NqIFCGOrhZzUTlRe8lPTzevyEj8eA8lm8eWwF9MMrabHanq'\n",
    "access_token = '982692299648925696-MlIqFRw5K8vNOmoGWD4bMoX0dpGo98n'\n",
    "access_secret = 'at2hhW8W6wGz3mmgxJPCJSnu0UC6wku4l9iJ4U5CzxTdI'\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret) \n",
    "api = tweepy.API(auth)\n",
    "user = api.me()\n",
    "\n",
    "##### Task 2.9 #####\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE) \n",
    "\n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Ejemplo de tokenisation\n",
    "#tweet = 'RT @JordiTorresBCN: just an example! :D http://JordiTorres.Barcelona #masterMEI'\n",
    "#print(preprocess(tweet))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mexico : 14\n",
      "Korea : 13\n",
      "AM : 12\n",
      "Brazil : 12\n",
      "Argentina : 12\n",
      "S : 12\n",
      "US : 12\n",
      "Indonesia : 12\n",
      "#IVoteBTSBBMAs : 10\n",
      "1 : 10\n",
      "\n",
      "\n",
      "#IVoteBTSBBMAs : 10\n",
      "\n",
      "\n",
      "Mexico : 14\n",
      "Korea : 13\n",
      "AM : 12\n",
      "Brazil : 12\n",
      "Argentina : 12\n",
      "S : 12\n",
      "US : 12\n",
      "Indonesia : 12\n",
      "1 : 10\n",
      "5 : 9\n"
     ]
    }
   ],
   "source": [
    "punctuation = list(string.punctuation)\n",
    "stop = stopwords.words('english') + punctuation + ['rt', 'via', 'RT','‚Ä¶']\n",
    "\n",
    "fname = 'ColombiaChileTweets.json'\n",
    "with open(fname, 'r') as f:\n",
    "    count_all = Counter()\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        # Create a list with all the terms\n",
    "        terms_stop = [term for term in preprocess(tweet['text']) if term not in stop]\n",
    "        count_all.update(terms_stop)\n",
    "    for word, index in count_all.most_common(10):\n",
    "        print ('%s : %s'%(word, index))\n",
    "    print ('\\n')\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    count_all_2 = Counter()\n",
    "    for line in f:\n",
    "        tweet2 = json.loads(line)\n",
    "        # Create a list with all the terms\n",
    "        terms_hash = [term for term in preprocess(tweet2['text']) if term.startswith('#')]\n",
    "        count_all_2.update(terms_hash)\n",
    "    for word, index in count_all_2.most_common(10):\n",
    "        print ('%s : %s'%(word, index))\n",
    "    print ('\\n')\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    count_all_3 = Counter()\n",
    "    for line in f:\n",
    "        tweet3 = json.loads(line)\n",
    "        # Create a list with all the terms\n",
    "        terms_only = [term for term in preprocess(tweet3['text']) \n",
    "              if term not in stop and not term.startswith(('#', '@'))] \n",
    "        count_all_3.update(terms_only)\n",
    "    for word, index in count_all_3.most_common(10):\n",
    "        print ('%s : %s'%(word, index))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 66), ('RT', 27), (':', 25), ('‚Ä¶', 19), ('Mexico', 14), ('Korea', 13), ('AM', 12), ('Brazil', 12), ('Argentina', 12), ('S', 12)]\n"
     ]
    }
   ],
   "source": [
    "fname = 'ColombiaChileTweets.json'\n",
    "with open(fname, 'r') as f:\n",
    "   count_all = Counter()\n",
    "   for line in f:\n",
    "       tweet = json.loads(line)\n",
    "       # Create a list with all the terms\n",
    "       terms_all = [term for term in preprocess(tweet['text'])]\n",
    "       # Update the counter\n",
    "       count_all.update(terms_all)\n",
    "   print(count_all.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@taxi_Tomasa', ':', 'muchas', 'aplicaciones', 'diruptivas', ',', 'utlizan', 'la', 'palabra', 'taxi', ',', 'para', 'promocionarsen', 'sin', 'serlo', ',', 'el', 'Taxi', 'tiene', 'un', 'taximetro', 'y', 'esta', '‚Ä¶']\n",
      "['RT', '@donyarous', ':', 'Un', 'estudi', 'de', '@lasaboga', 'conclou', 'que', 'a', \"l'Hospitalet\", 'creix', 'l', \"'\", '√∫s', 'de', 'la', 'bici', 'i', 'que', \"s'utilitza\", 'el', 'casc', 'el', 'doble', 'que', 'a', 'Barcelona', ',', 'e', '‚Ä¶']\n",
      "['RT', '@GaliciaBilingue', ':', 'Manifestaci', '√≥n', 'de', 'Hablamos', 'Espa', '√±ol', '.', 'Si', 'crees', 'en', 'la', 'libertad', ',', 'si', 'crees', 'que', 'se', 'debe', 'poder', 'estudiar', 'en', 'espa', '√±ol', 'en', 'cualquie', '‚Ä¶']\n",
      "['RT', '@GanaFalcon', ':', '\"', 'Quiz', '√°s', 'por', 'primera', 'vez', 'en', 'su', 'historia', ',', 'los', 'opositores', 'venezolanos', 'ser', '√°n', 'llamados', 'a', 'votar', 'no', 'con', 'el', 'coraz', '√≥n', ',', 'sino', 'con', 'la', 'me', '‚Ä¶']\n",
      "['RT', '@Pablo_Iglesias_', ':', 'Valtonyc', 'cant', '√≥', 'contra', 'el', 'Rey', ';', 'va', 'a', 'la', 'c√°rcel', '.', 'Losantos', 'dese', '√≥', 'pegarnos', 'un', 'tiro', 'y', 'bombardear', 'Barcelona', ';', 'seguir', '√°', 'despotr', '‚Ä¶']\n",
      "['RT', '@footballitalia', ':', 'La', 'Gazzetta', 'dello', 'Sport', 'states', 'that', \"#FIFA's\", 'new', 'Club', 'World', 'Cup', 'will', 'start', 'in', '2021,', 'featuring', '#Juventus', ',', '#ACMilan', ',', '#FCIM', '‚Ä¶']\n",
      "['@Spursito', 'Alg', '√∫n', 'equipo', 'europeo', 'que', 'te', 'guste', 'adem', '√°s', 'del', 'Barcelona', '?']\n",
      "['RT', '@eljueves', ':', 'Jim', '√©nez', 'Losantos', 'habla', 'de', 'bombardear', 'Barcelona', 'pero', ',', 'como', 'una', 'vez', 'm√°s', 'lo', 'hace', 'sin', 'rapear', ',', 'la', 'Audiencia', 'Nacional', 'est', '√°', 'atada', 'de', '‚Ä¶']\n",
      "['RT', '@eljueves', ':', 'Hoy', 'el', 'rapero', 'Valtonyc', 'entra', 'en', 'la', 'c√°rcel', 'mientras', 'Losantos', 'va', 'hablando', 'por', 'la', 'radio', 'de', 'bombardear', 'Barcelona', '.', 'Descubre', 'qu√©', 'ha', '‚Ä¶']\n",
      "['RT', '@NaomiBoitumelo', ':', 'Guys', 'which', 'one', 'is', 'true', 'Retweet', 'for', 'FC', 'Barcelona', 'vs', 'Mamelodi', 'Sundowns', 'Like', 'for', 'Real', 'Madrid', 'vs', 'Kaiser', 'Chiefs', 'https://t.co', '‚Ä¶']\n",
      "['RT', '@vox_alicante', ':', 'üì¢', 'vox_es', ':', 'RT', 'vox_es', ':', 'üìπ', 'Ortega_Smith', 'en', 'Barcelona', 'a', 'Quim', 'Torra', ':', '\"', 'Desde', 'VOX', 'te', 'perseguiremos', ',', 'te', 'sentaremos', 'en', 'el', 'banquillo', '‚Ä¶']\n",
      "['La', 'DO', 'Conca', 'de', 'Barber', '√†', 'va', 'triomfar', 'ahir', 'a', 'Barcelona', 'amb', 'un', 'showroom', 'al', 'qual', 'van', 'assistir', 'm√©s', 'de', '250', 'professionals', 'd', '‚Ä¶', 'https://t.co/Wwc5qPpqjY']\n",
      "['RT', '@RegGlass1', ':', 'Transfer', 'news', 'LIVE', 'updates', ':', 'Man', 'Utd', 'seal', '¬£', '50', 'm', 'deal', ',', 'Liverpool', ',', 'Chelsea', ',', 'Arsenal', ',', 'Barcelona', 'https://t.co/aA41EucDBq']\n",
      "['RT', '@Vidal_Ari11', ':', '@quirosdonoso', 'Saludos', 'Quir', '√≥s', 'hasta', 'Barcelona', '!', '!', 'üåç', 'üòä', 'üôã', 'https://t.co/OFWuaMdSR4']\n",
      "['@kenzieziegler', 'Come', 'to', 'Barcelona', 'i', 'want', 'to', 'meet', 'you', 'pleaseeee', ',', 'here', 'there', 'are', 'to', 'many', 'of', 'your', 'fans', 'üò¢', 'Sorry', 'for', 'my', 'en', '‚Ä¶', 'https://t.co/Xl3zXDAnlB']\n",
      "['RT', '@footballitalia', ':', 'La', 'Gazzetta', 'dello', 'Sport', 'states', 'that', \"#FIFA's\", 'new', 'Club', 'World', 'Cup', 'will', 'start', 'in', '2021,', 'featuring', '#Juventus', ',', '#ACMilan', ',', '#FCIM', '‚Ä¶']\n",
      "['RT', '@SmashBrosSpain', ':', 'El', 'segundo', 'confirmado', 'del', 'TOP', '10', 'espa', '√±ol', 'no', 'se', 'ha', 'hecho', 'esperar', '!', 'Directo', 'desde', 'Barcelona', ',', '@marcpq9', 'intentar', '√°', 'llevarse', '‚Ä¶']\n",
      "['RT', '@SmashBrosSpain', ':', 'El', 'segundo', 'confirmado', 'del', 'TOP', '10', 'espa', '√±ol', 'no', 'se', 'ha', 'hecho', 'esperar', '!', 'Directo', 'desde', 'Barcelona', ',', '@marcpq9', 'intentar', '√°', 'llevarse', '‚Ä¶']\n",
      "['@LidioDominante', 'Jejeje', 'y', 'me', 'recuerda', 'a', 'los', 'habitantes', 'de', 'Barcelona', 'que', 'ya', 'no', 'quieren', 'm√°s', 'turistas', 'Lo', 'que', 'hace', 'la', 'i', '‚Ä¶', 'https://t.co/kjRqOSXc10']\n",
      "['RT', '@MoneyRaised', ':', 'Barcelona', '‚Äô', 's', 'sneakers', 'brand', '@wearewado', 'has', 'raised', '‚Ç¨', '480.000', 'through', 'the', 'crowdfunding', 'platform', '@kickstarter', 'and', '@Indiegogo', '‚Ä¶']\n",
      "['RT', '@superwomanroja', ':', 'Pablo', 'Casado', 'pide', 'ilegalizar', 'los', 'partidos', 'independentistas', ',', 'C', '‚Äô', 's', 'mantener', 'el', '155', 'hasta', 'que', 'no', 'pidan', 'perd', '√≥n', ',', 'VOX', 'eliminar', '‚Ä¶']\n",
      "['RT', '@_shaunirvine', ':', 'Manchester', 'United', 'are', 'confident', 'of', 'beating', 'Chelsea', 'and', 'Barcelona', 'to', 'a', 'summer', 'deal', 'for', 'Tottenham', 'defender', 'Toby', 'Alderweirel', '‚Ä¶']\n",
      "['RT', '@Pablo_Iglesias_', ':', 'Valtonyc', 'cant', '√≥', 'contra', 'el', 'Rey', ';', 'va', 'a', 'la', 'c√°rcel', '.', 'Losantos', 'dese', '√≥', 'pegarnos', 'un', 'tiro', 'y', 'bombardear', 'Barcelona', ';', 'seguir', '√°', 'despotr', '‚Ä¶']\n",
      "['üö®', '18', 'heridos', 'al', 'caer', 'una', 'grada', 'del', 'plat', '√≥', 'de', '#Chester', 'en', '#Barcelona', 'https://t.co/X0R80zYObs']\n",
      "['RT', '@eljueves', ':', 'Hoy', 'el', 'rapero', 'Valtonyc', 'entra', 'en', 'la', 'c√°rcel', 'mientras', 'Losantos', 'va', 'hablando', 'por', 'la', 'radio', 'de', 'bombardear', 'Barcelona', '.', 'Descubre', 'qu√©', 'ha', '‚Ä¶']\n",
      "['Transfer', 'News', '!', 'Lionel', 'Messi', 'Names', '3', 'Players', 'That', 'Must', 'Leave', 'Barcelona', 'This', 'Summer', 'https://t.co/j41mZ6znOG', 'https://t.co/rBJmRNvtWb']\n",
      "['RT', '@Dolphin_Project', ':', 'ICYMI', ':', 'Barcelona', 'Spain', '‚Äô', 's', 'City', 'Council', 'has', 'officially', 'declared', 'that', 'it', 'will', 'not', 'allow', 'the', 'establishment', 'of', 'new', 'captive', '‚Ä¶']\n",
      "['El', 'ayuntamiento', 'de', 'Barcelona', 'pondr', '√°', 'la', 'bandera', 'loca', 'el', 'D√≠a', 'del', '#OrgulloLoco', 'https://t.co/47LQwu4dk9']\n",
      "['Susto', 'grande', 'en', '#Barcelona', 'en', 'una', 'entrevista', 'a', '#Iniesta', '.', 'Invitados', 'a', 'la', 'nota', ',', 'terminaron', 'heridos', '.', 'Varios', 'de', 'ellos', ',', '‚Ä¶', 'https://t.co/xMlgB1xQ65']\n",
      "['RT', '@RADIOSTARTERRAS', ':', 'Este', 'viernes', '@AbelPintos', ',', 'el', 'artista', 'argentino', 'm√°s', 'exitoso', 'del', 'momento', ',', 'visita', '@CronicasSonoras', 'de', '@ModeGallego', 'para', '‚Ä¶']\n",
      "['RT', '@RLouzad', ':', '@Houseof_CAT', 'i', 'jo', '.', '.', '.', 'totalment', \"d'acord\", '.', 'A', 'Barcelona', 'es', 'sent', 'parlar', 'ang', '√®s', ',', 'alem', '√†', 'itali', '√†', 'i', 'mil', 'lleng', '√ºes', 'm√©s', 'i', 'ning', '√∫', \"s'escarrissa\", '‚Ä¶']\n",
      "['RT', '@Historia_BSC', ':', '#UnDiaComoHoyBSC', '(', 'A√±o', '2016', ')', 'BARCELONA', 'S', '.', 'C', '.', '5', '‚Äì', '0', 'Emelec', 'Estadio', 'Monumental', '|', '50.000', 'personas', '|', 'Goles', ':', 'Pedro', 'Velasco', ',', 'Da', '‚Ä¶']\n",
      "['Bcn', '!', '!', '!', '!', '#Barcelona', '#Blackandwhitephotography', '#cityscapes', '#selfportrait', '#photography', '#streetart', '#streetphotography', '‚Ä¶', 'https://t.co/BHHkjBvAGZ']\n",
      "['RT', '@MomentsES', ':', '‚ö°', 'Ô∏è', 'La', 'era', 'de', 'Iniesta', 'en', 'el', 'Barcelona', 'llega', 'a', 'su', 'fin', 'y', 'todo', 'el', 'mundo', 'del', 'f√∫tbol', 'le', 'dice', ':', '\"', '¬°', 'Gracias', 'por', 'la', 'magia', ',', 'Don', 'Andr', '√©s', '!', '\"', '‚Ä¶']\n",
      "['RT', '@cracksdelfutboI', ':', 'La', 'camiseta', 'del', 'adi', '√≥s', '.', 'Barcelona', 'ha', 'creado', 'una', 'camiseta', 'especial', 'para', 'despedir', 'a', 'Andr', '√©s', 'Iniesta', 'La', 'afici', '√≥n', 'se', 'desped', '‚Ä¶']\n",
      "['RT', '@idmsamuel', ':', 'Aquele', 'aplicativo', 'que', '√©', 'jogador', 'do', 'Barcelona', 'o', 'lionel', 'messenger']\n",
      "['@AndreuYolanda', 'Yo', 's√≠', 'que', 'vaig', ',', 'vienen', 'els', 'meus', 'germans', 'de', 'Barcelona', 'y', 'ens', 'anem', 'de', 'torraeta', '.', 'Ummmm', 'che', 'qu√©', 'b√≥', '.', '.', '.']\n",
      "['RT', '@arenas_club1909', ':', '@jotajordi13', 'El', '@arenas_club1909', 'de', 'GETXO', ',', 'con', '109', 'a√±os', 'de', 'historia', ',', 'fund', '√≥', 'la', 'Primera', 'Divisi', '√≥n', ',', 'jug', '√≥', '7', 'temp', '.', 'en', '1', 'div', '‚Ä¶']\n",
      "['Announce', 'Atlantic', 'League', 'üëç', 'üèª', 'https://t.co/nO68lrzFFP']\n",
      "['I', 'dream', 'to', 'invite', 'Roger', 'Federer', 'to', 'Barcelona', '-', 'Ivan', 'Rakitic', '-', 'https://t.co/AF7yYMWy4d', 'via', '@Shareaholic']\n",
      "['@pepeblancoEP', '@Albert_Rivera', '@marianorajoy', '@CiudadanosCs', '@InesArrimadas', '@PSOE', 'Muy', 'democr', '√°tico', 'todo', '\\U0001f923', '\\U0001f923', '\\U0001f923', 'lo', 'de', 'bomba', '‚Ä¶', 'https://t.co/Pq3JORiaCs']\n",
      "['RT', '@ocultalit', ':', 'Joseph', 'Wilson', '(', 'EEUU', ',', '1977', ')', 'es', 'periodista', 'y', 'poeta', '.', 'Vive', 'en', 'Barcelona', 'desde', 'el', 'a√±o', '2000,', 'donde', 'trabaja', 'como', 'corresponsal', 'The', 'A', '‚Ä¶']\n",
      "['Dependient', '@s', '#Empleo', '#Barcelona', 'https://t.co/LpCsKTzJr8']\n",
      "['RT', '@PureFitbaw', ':', 'üè¥', '\\U000e0067', '\\U000e0062', '\\U000e0073', '\\U000e0063', '\\U000e0074', '\\U000e007f', '‚öΩ', 'Ô∏è', '‚Äú', 'Standard', 'of', 'defending', 'is', 'shocking', '‚Äù', 'Hibs', '5', '-', 'Rangers', '5', 'üá™', 'üá∏', '‚öΩ', 'Ô∏è', '‚Äú', 'Expansive', ',', 'free', 'flowing', ',', 'attacking', 'football', '‚Äù', '‚Ä¶']\n",
      "['RT', '@TrollFootball', ':', 'Levante', 'is', 'now', 'called', 'Evante', '.', 'They', 'gave', 'the', 'L', 'to', 'Barcelona', 'https://t.co/VZaFw6VWVg']\n",
      "['RT', '@GeorgeMarkton', ':', 'First', 'player', 'to', 'score', 'a', 'hat-trick', 'against', 'Barcelona', 'in', '13', 'years', ',', \"Ghana's\", 'Emmanuel', 'Boateng', \"'\", 'RECORD', '!', '!', 'üëä', 'https://t.co/puiQ', '‚Ä¶']\n"
     ]
    }
   ],
   "source": [
    "with open('ColombiaChileTweets.json', 'r') as f:\n",
    "    import io\n",
    "    f=io.open('data/stream_barcelona.json', 'r', encoding='utf8' )\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        tokens = preprocess(tweet['text'])\n",
    "        print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Task 2.10 ########\n",
    "\n",
    "class TweeterListener(StreamListener):\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            with open('stream_barcelona.json', 'a') as f:\n",
    "                f.write(data)\n",
    "                return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True\n",
    "    \n",
    "twitter_stream = Stream(auth, TweeterListener())\n",
    "twitter_stream.filter(track=['Barcelona'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Task 2.11 #####\n",
    "\n",
    "with open('ColombiaChileTweets.json','r') as json_file:\n",
    "         for line in json_file:\n",
    "             tweet = json.loads(line)\n",
    "             print(tweet[\"text\"])\n",
    "\n",
    "with open('ColombiaChileTweets.json', 'r') as f:\n",
    "    line = f.readline() \n",
    "    tweet = json.loads(line) \n",
    "    print(json.dumps(tweet, indent=4)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
